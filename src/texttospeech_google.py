import os
from typing import List, Tuple

import proto  # type: ignore
from google.cloud import texttospeech_v1beta1 as texttospeech
from google.cloud.texttospeech_v1beta1.types.cloud_tts import (
    SynthesizeSpeechRequest,
)

from credentials import GOOGLE_JSON_PATH
from generate_audio import play_audio
from generate_subtitle import generate_subtitle_file
from utils import words_length

import ctypes

VLC_PATH = "C:\\Program Files\\VideoLAN\\VLC"  # VLCê°€ ì„¤ì¹˜ëœ ê²½ë¡œ í™•ì¸ í›„ ìˆ˜ì •
os.add_dll_directory(VLC_PATH)  # DLL ê²½ë¡œ ì¶”ê°€
ctypes.CDLL(os.path.join(VLC_PATH, "libvlc.dll"))  # VLC ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ

import vlc

os.environ["BASE_DIR_PATH"] = r"C:\Users\halo0\Desktop\leonproject\ai-bj\test_api\Kuebiko-main\vtube_test\src"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = GOOGLE_JSON_PATH


def _config_texttospeech_request(text_to_transform_to_audio: str) -> Tuple[SynthesizeSpeechRequest, List[str]]:
    ssml_text = "<speak>"
    response_counter = 0
    mark_array: List[str] = []

    for s in text_to_transform_to_audio.split(" "):
        ssml_text += f'<mark name="{response_counter}"/>{s}<break time="0.15s"/>'
        mark_array.append(s)
        response_counter += 1
    ssml_text += "</speak>"

    input_text = texttospeech.SynthesisInput(ssml=ssml_text)

    voice = texttospeech.VoiceSelectionParams(
        language_code="es-US",
        name="es-US-Neural2-A",
    )

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        pitch=4,
        speaking_rate=0.9,
    )

    SSML_MARK = proto.RepeatedField(
        proto_type=proto.ENUM,
        enum=SynthesizeSpeechRequest.TimepointType,
        number=SynthesizeSpeechRequest.TimepointType.SSML_MARK,
        message="SSML_MARK",
    )
    # enable_time_pointingì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìˆ˜ì •
    speech_request = SynthesizeSpeechRequest(
        input=input_text,
        voice=voice,
        audio_config=audio_config,
        enable_time_pointing=[SynthesizeSpeechRequest.TimepointType.SSML_MARK]  # ë¦¬ìŠ¤íŠ¸ë¡œ ìˆ˜ì •
    )
    return (speech_request, mark_array)


def generate_audio_and_subtitle(user_question: str, audio_filename="audio.mp3"):
    text_to_transform_to_audio = user_question
    print(f"Character length = {len(text_to_transform_to_audio)}")
    print(f"Words length = {words_length(text_to_transform_to_audio)}")

    client = texttospeech.TextToSpeechClient()
    request, mark_array = _config_texttospeech_request(text_to_transform_to_audio)
    response = client.synthesize_speech(request=request)

    play_audio(audio_filename, response.audio_content)
    subtitle_file = generate_subtitle_file(response.timepoints, mark_array)

    #print(f"ğŸ“œ ìƒì„±ëœ ìë§‰ íŒŒì¼: {subtitle_file}")


### ğŸš€ **í„°ë¯¸ë„ì—ì„œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ìŒì„± ì¶œë ¥ ë° ìë§‰ ìƒì„±**
def main():
    print(" ìŒì„± ë³€í™˜ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘... (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")

    while True:
        user_input = input("\n ì‚¬ìš©ì ì…ë ¥: ")
        if user_input.lower() == "exit":
            print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ!")
            break

        generate_audio_and_subtitle(user_input)


if __name__ == "__main__":
    main()
