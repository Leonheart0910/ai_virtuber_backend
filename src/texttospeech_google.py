import os
from typing import List, Tuple
import proto  # type: ignore
from google.cloud import texttospeech_v1beta1 as texttospeech
from google.cloud.texttospeech_v1beta1.types.cloud_tts import SynthesizeSpeechRequest

# âœ… GPT ì‘ë‹µì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ gpt_test.py ëª¨ë“ˆ import
from gpt_test import generate_gpt_response

from credentials import GOOGLE_JSON_PATH
from generate_audio import play_audio
from generate_subtitle import generate_subtitle_file
from utils import words_length

import ctypes

# âœ… VLC ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì„¤ì •
VLC_PATH = "C:\\Program Files\\VideoLAN\\VLC"
os.add_dll_directory(VLC_PATH)
ctypes.CDLL(os.path.join(VLC_PATH, "libvlc.dll"))

import vlc

# âœ… Google Cloud API ì¸ì¦ ì •ë³´ ì„¤ì •
os.environ["BASE_DIR_PATH"] = r"C:\Users\82109\Desktop\BJ_sena\sena\ai_virtuber_backend\src"
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = GOOGLE_JSON_PATH


def _config_texttospeech_request(text_to_transform_to_audio: str) -> Tuple[SynthesizeSpeechRequest, List[str]]:
    ssml_text = "<speak>"
    response_counter = 0
    mark_array: List[str] = []

    for s in text_to_transform_to_audio.split(" "):
        ssml_text += f'<mark name="{response_counter}"/>{s}<break time="0.15s"/>'
        mark_array.append(s)
        response_counter += 1
    ssml_text += "</speak>"

    input_text = texttospeech.SynthesisInput(ssml=ssml_text)

    # âœ… **í•œêµ­ì–´ ìŒì„± ëª¨ë¸ ì ìš©**
    voice = texttospeech.VoiceSelectionParams(
        language_code="ko-KR",  # âœ… í•œêµ­ì–´ ì ìš©
        name="ko-KR-Neural2-A",  # âœ… í•œêµ­ì–´ ìŒì„± ëª¨ë¸ (ë‹¤ë¥¸ ì˜µì…˜: "ko-KR-Wavenet-A")
    )

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        pitch=0,  # âœ… ê¸°ë³¸ ìŒë†’ì´ (ë” ë‚®ì¶”ë ¤ë©´ -2, ë†’ì´ë©´ +2)
        speaking_rate=1.0,  # âœ… ê¸°ë³¸ ì†ë„ (ë” ë¹ ë¥´ê²Œ: 1.2, ë” ëŠë¦¬ê²Œ: 0.85)
    )

    # âœ… enable_time_pointingì„ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ìˆ˜ì •
    speech_request = SynthesizeSpeechRequest(
        input=input_text,
        voice=voice,
        audio_config=audio_config,
        enable_time_pointing=[SynthesizeSpeechRequest.TimepointType.SSML_MARK]
    )
    return speech_request, mark_array


def generate_audio_and_subtitle(user_input: str, audio_filename="audio.mp3"):
    """ğŸ¤ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ GPT ì‘ë‹µ í›„ ìŒì„± ë³€í™˜"""
    # âœ… GPT ì‘ë‹µ ìƒì„±
    gpt_response = generate_gpt_response(user_input)

    print(f"ğŸ“œ GPT Response: {gpt_response}")
    print(f"Character length = {len(gpt_response)}")
    print(f"Words length = {words_length(gpt_response)}")

    client = texttospeech.TextToSpeechClient()
    request, mark_array = _config_texttospeech_request(gpt_response)
    response = client.synthesize_speech(request=request)

    play_audio(audio_filename, response.audio_content)
    subtitle_file = generate_subtitle_file(response.timepoints, mark_array)

    #print(f"ğŸ“œ ìƒì„±ëœ ìë§‰ íŒŒì¼: {subtitle_file}")


### ğŸš€ **í„°ë¯¸ë„ì—ì„œ ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ GPT ì‘ë‹µ í›„ ìŒì„± ì¶œë ¥**
def main():
    print(" ğŸ¤ ìŒì„± ë³€í™˜ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘... (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥)")

    while True:
        user_input = input("\n ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥: ")
        if user_input.lower() == "exit":
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ ì¢…ë£Œ!")
            break

        generate_audio_and_subtitle(user_input)


if __name__ == "__main__":
    main()
